# 캐시 메모리

## 캐시 메모리란?

CPU와 주기억장치 사이에 위치한 고속의 임시 저장 장치

CPU가 더 빠르게 데이터를 처리할 수 있도록 자주 사용하거나 곧 사용할 데이터를 저장하여 메모리 접근 시간을 단축시키는 역할을 한다.

프로세서의 클럭 속도가 너무 빨라져 메인 메모리와의 속도 차이로 인해 발생하는 병목 현상을 완화하기 위해 사용된다.

## 캐시 메모리의 주요 특징

#### 고속 접근 속도

캐시 메모리는 메인 메모리보다 훨씬 빠른 속도를 제공한다. 이를 통해 CPU가 데이터를 더 빨리 읽고 쓸 수 있다.

#### 작은 용량

캐시 메모리는 물리적 크기와 비용 문제로 인해 메인 메모리보다 용량이 훨씬 작다.

## SRAM과 DRAM

### SRAM(Static Random Access Memory)

SRAM은 비교적 빠른 속도를 가지고 있지만, 고가로 제작되는 메모리이다.

주로 CPU 내부의 캐시 메모리로 사용된다.


### DRAM(Dynamic Random Access Memory)

DRAM은 SRAM에 비해 속도가 느리지만, SRAM에 비해 저렴하게 제작되는 메모리이다.

데이터 유지를 위해 주기적으로 새로고침해야 한다.

주로 주 기억장치(메인 메모리)로 사용된다.(L1, L2, L3 캐시 메모리는 SRAM을 사용)

#### 계층 구조
캐시 메모리는 CPU와 메인 메모리 사이의 속도 차이를 줄이기 위해 여러 단계(L1, L2, L3)로 구분된다.

L1 캐시: CPU 내부에 위치하며 가장 빠르지만 용량이 가장 작다.

L2 캐시: CPU 내부 또는 외부에 위치하며, L1보다 느리지만 용량이 크다.

L3 캐시: CPU 외부에 위치하며, L2보다 느리지만 상대적으로 더 큰 용량을 갖는다.

일반적으로 L1, L2 캐시는 코어 내부에 존재하고 L3 캐시는 코어 외부에 존재한다.

멀티코어 프로세서에서는 코어마다 각각 L1, L2 캐시를 가지고 있고, 모든 코어가 공유하는 L3 캐시가 존재한다.




#### 지역성(Locality) 원리 활용

캐시는 프로그램 실행 시 데이터 접근 패턴에 따른 지역성의 원리를 활용한다.

시간 지역성(Temporal Locality): 최근에 접근한 데이터는 곧 다시 접근될 가능성이 높다.

공간 지역성(Spatial Locality): 접근한 데이터와 인접한 데이터도 곧 접근될 가능성이 높다.

#### 히트(Hit)와 미스(Miss)

캐시 히트(Cache Hit): CPU가 원하는 데이터가 캐시 메모리에 존재할 경우.

캐시 미스(Cache Miss): CPU가 원하는 데이터가 캐시 메모리에 없을 경우, 메인 메모리에서 데이터를 가져와야 한다.



## Cache Memory의 접근 정책

CPU에서 메모리에 읽기 요청을 하게 되면 먼저 캐시에 그 해당 데이터가 있는 확인한다. 

이 과정에서 그 데이터가 있는 경우 Hit했다고 하여 그 해당 데이터를 가져오게 된다. 

이 Hit를 위해서 언제 어떤 방식으로 어떤 데이터를 Cache Memory에 적재해둘 것인가 가 Hit 율을 좌우하고 성능의 관심사가 된다. 


### 직접 매핑(Direct Mapping)

캐시 메모리의 한 블록은 메인 메모리의 한 블록과 대응된다.

메인 메모리의 주소를 캐시 메모리의 주소로 변환하는데, 이때 변환된 주소의 일부 비트를 캐시 메모리의 인덱스로 사용한다.

가장 저렴하다.

위와 같은 방법은 충돌이 자주 발생 따라서 아래의 2가지 방법을 사용하기도 함




### 완전 연관 매핑 Full Associative Mapping

메모리의 어떤 블록이라도 캐시 메모리의 어떤 위치에 저장될 수 있다.

충돌이 거의 없고 캐시 활용도가 높지만, 하드웨어 복잡도가 높고, 비용이 비싸다


### 집합 연관 매핑 Set Associative Mapping

캐시를 여러개의 집합으로 나누고, 각 집합은 여러 개의 캐시 라인으로 구성된다.

충동이 적고 캐시 활용도 적절하다.

구현 복잡도도 중간이고 접근 시간이 증가할 수 있다.

비용은 중간 수준이다.


## Cache Memory의 실패 처리

1. 원래의 PC(현재 pc 값 - 4)값을 메모리로 보낸다.
2. 메인 메모리에 읽기 동작을 지시하고 메모리가 접근을 끝낼 때 까지 기다린다.
3. 메모리에서 인출한 데이터를 데이터부분에 쓰고, 태그 필드에 주소(ALU로 부터 계산된)의 상위 비트를 쓰고 유효 비트를 1로 만듦으로써 캐시 엔드리에 쓰기를 수행한다.
4. 명령어 수행을 첫 단계부터 다시 시작하여 캐시에서 명령어를 가져온다. 이제는 필요한 명령어를 캐시에서 찾을 수 있다.



## Cache Memory의 쓰기 정책 

### 즉시 쓰기(Write Through)

캐시에 데이터를 쓸 때 메인 메모리에도 즉시 데이터를 반영하는 방삭

설계가 잘 되었다고 해도 좋은 성능을 내기 어려움
-> 모든 캐시 쓰기가 메인 메모리에 데이터를 써야하기 때문

위와 같은 문제를 해결하기 위해 쓰기 버퍼를 이용한다.

#### 쓰기 버퍼(Write Buffer)
쓰기 버퍼는 메모리에 쓰이기 위해 기다리는 동안 데이터를 저장

메인 메모리에 쓰기를 완료하고 나면, 쓰기 버퍼는 다시 비워짐

하지만 쓰기 버퍼가 가득 차면  버퍼에 빈 공간이 생길 때까지 캐시 쓰기를 지연시켜야 하므로 성능 저하가 발생할 수 있다.


### 다중 쓰기(Write Back)

쓰기가 발생했을 때 새로운 값은 캐시 내의 블록에만 쓰고, 나중에 캐시에서 쫓겨날 때 쓰기에 의해 내용이 변경된 블록만 메인 메모리에 쓰는 방식






